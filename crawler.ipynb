{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scraped: 150\n",
      "Last Tweet: {'Doc_id': 282913163, 'Message': '$BABA my reaction to those that sold yesterday.', 'Date': '2021-02-03', 'Time': '06:48:55Z', 'Sentiment': 'Bullish'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "def scraper(ticker, latest_xhr_id='0', max_volume=50000, start_date='2020-01-01', end_date='2020-12-31'):\n",
    "\n",
    "    \n",
    "    inv_table = {}\n",
    "    \n",
    "    # Push Errors if scrape volume less than 0:\n",
    "    if max_volume <= 0:\n",
    "        sys.exit(\"Error: max_volume must be more than 0\")\n",
    "\n",
    "    start = time.time()\n",
    "    master_content = []  # List to store all data extracted\n",
    "    scroll_list = [latest_xhr_id]  # List to store all XHR id to be part of the url parameters\n",
    "    tracker_list = []  # List containing integers for tracking progress\n",
    "    tracker = 0\n",
    "    fail_count = 0\n",
    "\n",
    "    for x in range(5001):\n",
    "        if x > 0:\n",
    "            addition = x * 100\n",
    "            tracker_list.append(addition)\n",
    "\n",
    "    # Running for loop for collecting data from stocktwits. Each loop collects 20 comments.\n",
    "    for _ in range(max_volume):\n",
    "        try:\n",
    "            headers = {\n",
    "                'authority': 'api.stocktwits.com',\n",
    "                'accept': 'application/json',\n",
    "                'authorization': 'OAuth 6439333424451d1c85e731fb126006f7780192d2',\n",
    "                'user-agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                               'Chrome/87.0.4280.88 Safari/537.36'),\n",
    "                'origin': 'https://stocktwits.com',\n",
    "                'sec-fetch-site': 'same-site',\n",
    "                'sec-fetch-mode': 'cors',\n",
    "                'sec-fetch-dest': 'empty',\n",
    "                'referer': 'https://stocktwits.com/',\n",
    "                'accept-language': 'en-US,en;q=0.9',\n",
    "            }\n",
    "\n",
    "            params = (\n",
    "                ('symbols',ticker),\n",
    "                ('filter', 'all'),\n",
    "                ('limit', '30'),\n",
    "                ('max', scroll_list[-1]),\n",
    "            )\n",
    "\n",
    "            response = requests.get(f'https://api.stocktwits.com/api/2/streams/symbols.json',\n",
    "                                    headers=headers, params=params)\n",
    "            content = response.json()\n",
    "            messages = content['messages']\n",
    "            # Creating dictionary for items scraped\n",
    "            for item in messages:\n",
    "                content_dict = {}\n",
    "                content_dict['Doc_id'] = item['id']\n",
    "                content_dict['Message'] = item['body']\n",
    "                content_dict['Date'] = item['created_at'].split('T')[0]\n",
    "                content_dict['Time'] = item['created_at'].split('T')[1]\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    content_dict['Sentiment'] = item['entities']['sentiment']['basic']\n",
    "                except TypeError:\n",
    "                    content_dict['Sentiment'] = \"N/A\"\n",
    "                    \n",
    "                for i in range(len(item['symbols'])):\n",
    "                    label = item['symbols'][i]['symbol']\n",
    "                    \n",
    "                    if label in inv_table:\n",
    "                        inv_table[label].append(content_dict['Doc_id'])\n",
    "                    else:\n",
    "                        inv_table[label] = [content_dict['Doc_id']]\n",
    "\n",
    "                master_content.append(content_dict.copy())\n",
    "                    \n",
    "\n",
    "            next_20_id = str(messages[-1]['id'])\n",
    "            scroll_list.append(next_20_id)\n",
    "\n",
    "            # Progress Tracker\n",
    "            tracker += 1\n",
    "\n",
    "            # Variables for tracker\n",
    "            last_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "            first_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "\n",
    "            diff = last_date - first_date\n",
    "\n",
    "            three_quarter_done = first_date + diff/4\n",
    "            half_done = first_date + diff/2\n",
    "            one_quarter_done = first_date + diff*3/4\n",
    "\n",
    "            # Trackers\n",
    "            for number in tracker_list:\n",
    "                if tracker == number:\n",
    "                    print(f\"Extracted {number}...\")\n",
    "                    print(f\"run time = {time.time() - start}\")  # Check run time\n",
    "\n",
    "            if (master_content[-1]['Time'].split(\":\")[0] == \"00\" and\n",
    "                    master_content[-1]['Date'] == f'{one_quarter_done}'):\n",
    "                print(\"25% done\")\n",
    "\n",
    "            elif (master_content[-1]['Time'].split(\":\")[0] == \"00\" and\n",
    "                    master_content[-1]['Date'] == f'{half_done}'):\n",
    "                print(\"50% done\")\n",
    "\n",
    "            elif (master_content[-1]['Time'].split(\":\")[0] == \"00\" and\n",
    "                    master_content[-1]['Date'] == f'{three_quarter_done}'):\n",
    "                print(\"75% done\")\n",
    "\n",
    "            elif (master_content[-1]['Time'].split(\":\")[0] == \"00\" and\n",
    "                    master_content[-1]['Date'] == f'{first_date}'):\n",
    "                print(\"100% done\")\n",
    "                print(f'Number of tweets unable to scrape: {fail_count * 20}')\n",
    "                break\n",
    "\n",
    "        except:\n",
    "            fail_count += 1\n",
    "\n",
    "    print(f\"Number of tweets scraped: {len(master_content)}\")\n",
    "    print(f\"Last Tweet: {master_content[-1]}\")\n",
    "\n",
    "    df = pd.DataFrame(master_content)\n",
    "    \n",
    "    for i in inv_table:\n",
    "        inv_table[i].sort()\n",
    "        \n",
    "    return df,inv_table\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tweets_df,inv_table = scraper (\"AAPL,BABA\",max_volume = 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BABA': [282913163,\n",
       "  282913276,\n",
       "  282913374,\n",
       "  282913484,\n",
       "  282913561,\n",
       "  282913615,\n",
       "  282914030,\n",
       "  282914424,\n",
       "  282914597,\n",
       "  282914907,\n",
       "  282915494,\n",
       "  282915925,\n",
       "  282916264,\n",
       "  282916513,\n",
       "  282916696,\n",
       "  282918524,\n",
       "  282918713,\n",
       "  282918873,\n",
       "  282918974,\n",
       "  282919382,\n",
       "  282920118,\n",
       "  282922822,\n",
       "  282922829,\n",
       "  282922846,\n",
       "  282922854,\n",
       "  282922884,\n",
       "  282923160,\n",
       "  282923171,\n",
       "  282923179,\n",
       "  282923574,\n",
       "  282923575,\n",
       "  282923626,\n",
       "  282923785,\n",
       "  282923811,\n",
       "  282923928,\n",
       "  282923937,\n",
       "  282923950,\n",
       "  282924299,\n",
       "  282924324,\n",
       "  282924331,\n",
       "  282924337,\n",
       "  282924419,\n",
       "  282924584,\n",
       "  282924598,\n",
       "  282924754,\n",
       "  282924779,\n",
       "  282924860,\n",
       "  282925011,\n",
       "  282925084,\n",
       "  282925092,\n",
       "  282925150,\n",
       "  282925198,\n",
       "  282925205,\n",
       "  282925283,\n",
       "  282925335,\n",
       "  282925387,\n",
       "  282925436,\n",
       "  282925547,\n",
       "  282925595,\n",
       "  282925649,\n",
       "  282925743,\n",
       "  282925781,\n",
       "  282925845,\n",
       "  282925916,\n",
       "  282925940,\n",
       "  282925958,\n",
       "  282925975,\n",
       "  282926198,\n",
       "  282926248,\n",
       "  282926335,\n",
       "  282926352,\n",
       "  282926390,\n",
       "  282926402,\n",
       "  282926439,\n",
       "  282926440,\n",
       "  282926486,\n",
       "  282926510,\n",
       "  282926537,\n",
       "  282926561,\n",
       "  282926588,\n",
       "  282926643,\n",
       "  282926669,\n",
       "  282926722,\n",
       "  282926819,\n",
       "  282926876,\n",
       "  282926925,\n",
       "  282926939,\n",
       "  282926997,\n",
       "  282926999,\n",
       "  282927034,\n",
       "  282927036,\n",
       "  282927083,\n",
       "  282927113,\n",
       "  282927166,\n",
       "  282927282,\n",
       "  282927525,\n",
       "  282927806,\n",
       "  282927818,\n",
       "  282927821,\n",
       "  282927843,\n",
       "  282928148,\n",
       "  282928314,\n",
       "  282928411,\n",
       "  282929133,\n",
       "  282929147,\n",
       "  282929246,\n",
       "  282929423,\n",
       "  282929437,\n",
       "  282929450],\n",
       " 'AAPL': [282913385,\n",
       "  282913876,\n",
       "  282914556,\n",
       "  282914906,\n",
       "  282915711,\n",
       "  282915804,\n",
       "  282915885,\n",
       "  282917164,\n",
       "  282917377,\n",
       "  282917646,\n",
       "  282918052,\n",
       "  282918141,\n",
       "  282918453,\n",
       "  282918593,\n",
       "  282918759,\n",
       "  282919248,\n",
       "  282919497,\n",
       "  282919745,\n",
       "  282920352,\n",
       "  282920458,\n",
       "  282920550,\n",
       "  282920673,\n",
       "  282921784,\n",
       "  282921888,\n",
       "  282921904,\n",
       "  282923362,\n",
       "  282924313,\n",
       "  282924448,\n",
       "  282924561,\n",
       "  282924690,\n",
       "  282925095,\n",
       "  282925165,\n",
       "  282925204,\n",
       "  282925263,\n",
       "  282925427,\n",
       "  282926264,\n",
       "  282926621,\n",
       "  282926666,\n",
       "  282927490,\n",
       "  282927771,\n",
       "  282928599],\n",
       " 'GME': [282925165, 282925204, 282928599],\n",
       " 'NOK': [282928599],\n",
       " 'AMC': [282915885, 282925165, 282925204, 282928599],\n",
       " 'SPY': [282913385,\n",
       "  282913876,\n",
       "  282914906,\n",
       "  282914907,\n",
       "  282916264,\n",
       "  282923179,\n",
       "  282923362,\n",
       "  282925095,\n",
       "  282926264,\n",
       "  282926561,\n",
       "  282926666,\n",
       "  282928314],\n",
       " 'NIO': [282917377, 282927490, 282927771],\n",
       " 'TSLA': [282913385,\n",
       "  282914906,\n",
       "  282917377,\n",
       "  282918759,\n",
       "  282919497,\n",
       "  282923362,\n",
       "  282925095,\n",
       "  282925263,\n",
       "  282926264,\n",
       "  282926666,\n",
       "  282927490,\n",
       "  282927771],\n",
       " 'MSFT': [282917164, 282918052, 282926666],\n",
       " 'AMZN': [282913876, 282914556, 282926621],\n",
       " 'AMD': [282914907, 282916264, 282923179, 282926264, 282926561],\n",
       " 'AAL': [282913385, 282914907, 282916264, 282923179, 282926561],\n",
       " 'SPCE': [282914907, 282915885, 282916264, 282923179, 282926561],\n",
       " 'BA': [282914906, 282923362, 282925263, 282926264],\n",
       " 'FCEL': [282914906, 282923362, 282925263],\n",
       " 'QQQ': [282925263],\n",
       " 'MA': [282924448, 282925204],\n",
       " 'V': [282924448, 282925204],\n",
       " 'SAVA': [282925095],\n",
       " 'COST': [282920118],\n",
       " 'CCIV': [282920118],\n",
       " 'NNDM': [282918524, 282919497],\n",
       " 'FRSX': [282919497],\n",
       " 'HYMTF': [282919248],\n",
       " 'DOGE.X': [282915885],\n",
       " 'RYCEY': [282915885],\n",
       " 'PSTH': [282914556],\n",
       " 'PLUG': [282913385]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(r'Database.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
